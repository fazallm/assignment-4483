{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar_10_data(data_dir, negatives=False):\n",
    "    \"\"\"\n",
    "    Return train_data, train_filenames, train_labels, test_data, test_filenames, test_labels\n",
    "    \"\"\"\n",
    "\n",
    "    # get the meta_data_dict\n",
    "    # num_cases_per_batch: 1000\n",
    "    # label_names: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "    # num_vis: :3072\n",
    "\n",
    "    meta_data_dict = unpickle(data_dir + \"/batches.meta\")\n",
    "    cifar_label_names = meta_data_dict[b'label_names']\n",
    "    cifar_label_names = np.array(cifar_label_names)\n",
    "\n",
    "    # training data\n",
    "    cifar_train_data = None\n",
    "    cifar_train_filenames = []\n",
    "    cifar_train_labels = []\n",
    "\n",
    "    # cifar_train_data_dict\n",
    "    # 'batch_label': 'training batch 5 of 5'\n",
    "    # 'data': ndarray\n",
    "    # 'filenames': list\n",
    "    # 'labels': list\n",
    "\n",
    "    for i in range(1, 6):\n",
    "        cifar_train_data_dict = unpickle(data_dir + \"/data_batch_{}\".format(i))\n",
    "        if i == 1:\n",
    "            cifar_train_data = cifar_train_data_dict[b'data']\n",
    "        else:\n",
    "            cifar_train_data = np.vstack((cifar_train_data, cifar_train_data_dict[b'data']))\n",
    "        cifar_train_filenames += cifar_train_data_dict[b'filenames']\n",
    "        cifar_train_labels += cifar_train_data_dict[b'labels']\n",
    "\n",
    "    cifar_train_data = cifar_train_data.reshape((len(cifar_train_data), 3, 32, 32))\n",
    "    if negatives:\n",
    "        cifar_train_data = cifar_train_data.transpose(0, 2, 3, 1).astype(np.float32)\n",
    "    else:\n",
    "        cifar_train_data = np.rollaxis(cifar_train_data, 1, 4)\n",
    "    cifar_train_filenames = np.array(cifar_train_filenames)\n",
    "    cifar_train_labels = np.array(cifar_train_labels)\n",
    "\n",
    "    # test data\n",
    "    # cifar_test_data_dict\n",
    "    # 'batch_label': 'testing batch 1 of 1'\n",
    "    # 'data': ndarray\n",
    "    # 'filenames': list\n",
    "    # 'labels': list\n",
    "\n",
    "    cifar_test_data_dict = unpickle(data_dir + \"/test_batch\")\n",
    "    cifar_test_data = cifar_test_data_dict[b'data']\n",
    "    cifar_test_filenames = cifar_test_data_dict[b'filenames']\n",
    "    cifar_test_labels = cifar_test_data_dict[b'labels']\n",
    "\n",
    "    cifar_test_data = cifar_test_data.reshape((len(cifar_test_data), 3, 32, 32))\n",
    "    if negatives:\n",
    "        cifar_test_data = cifar_test_data.transpose(0, 2, 3, 1).astype(np.float32)\n",
    "    else:\n",
    "        cifar_test_data = np.rollaxis(cifar_test_data, 1, 4)\n",
    "    cifar_test_filenames = np.array(cifar_test_filenames)\n",
    "    cifar_test_labels = np.array(cifar_test_labels)\n",
    "\n",
    "    return cifar_train_data, cifar_train_filenames, cifar_train_labels, \\\n",
    "        cifar_test_data, cifar_test_filenames, cifar_test_labels, cifar_label_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " cifar_10_dir = './data/cifar-10-batches-py'\n",
    "\n",
    "train_data, train_filenames, train_labels, test_data, test_filenames, test_labels, label_names = load_cifar_10_data(cifar_10_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 28.,  25.,  10.],\n",
       "         [ 37.,  34.,  19.],\n",
       "         [ 38.,  35.,  20.],\n",
       "         ...,\n",
       "         [ 76.,  67.,  39.],\n",
       "         [ 81.,  72.,  43.],\n",
       "         [ 85.,  76.,  47.]],\n",
       "\n",
       "        [[ 33.,  28.,  13.],\n",
       "         [ 34.,  30.,  14.],\n",
       "         [ 32.,  27.,  12.],\n",
       "         ...,\n",
       "         [ 95.,  82.,  55.],\n",
       "         [ 96.,  82.,  56.],\n",
       "         [ 85.,  72.,  45.]],\n",
       "\n",
       "        [[ 39.,  32.,  15.],\n",
       "         [ 40.,  33.,  17.],\n",
       "         [ 57.,  50.,  33.],\n",
       "         ...,\n",
       "         [ 93.,  76.,  52.],\n",
       "         [107.,  89.,  66.],\n",
       "         [ 95.,  77.,  54.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 83.,  73.,  52.],\n",
       "         [ 87.,  77.,  56.],\n",
       "         [ 84.,  74.,  52.],\n",
       "         ...,\n",
       "         [ 99.,  93.,  70.],\n",
       "         [ 90.,  84.,  61.],\n",
       "         [ 81.,  75.,  52.]],\n",
       "\n",
       "        [[ 88.,  72.,  51.],\n",
       "         [ 90.,  74.,  52.],\n",
       "         [ 93.,  77.,  56.],\n",
       "         ...,\n",
       "         [ 80.,  74.,  53.],\n",
       "         [ 76.,  70.,  49.],\n",
       "         [ 82.,  76.,  55.]],\n",
       "\n",
       "        [[ 97.,  78.,  56.],\n",
       "         [ 94.,  75.,  53.],\n",
       "         [ 93.,  75.,  53.],\n",
       "         ...,\n",
       "         [ 54.,  47.,  28.],\n",
       "         [ 63.,  56.,  37.],\n",
       "         [ 72.,  65.,  46.]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(train_data[3], dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleAttributeError",
     "evalue": "'Conv2d' object has no attribute 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleAttributeError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-effc3aa64360>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1-effc3aa64360>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxavier_uniform_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxavier_uniform_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxavier_uniform_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\test\\lib\\site-packages\\torch\\nn\\init.py\u001b[0m in \u001b[0;36mxavier_uniform_\u001b[1;34m(tensor, gain)\u001b[0m\n\u001b[0;32m    306\u001b[0m         \u001b[1;33m>>\u001b[0m\u001b[1;33m>\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxavier_uniform_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalculate_gain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m     \"\"\"\n\u001b[1;32m--> 308\u001b[1;33m     \u001b[0mfan_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfan_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_calculate_fan_in_and_fan_out\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    309\u001b[0m     \u001b[0mstd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgain\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2.0\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfan_in\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfan_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3.0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mstd\u001b[0m  \u001b[1;31m# Calculate uniform bounds from standard deviation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\test\\lib\\site-packages\\torch\\nn\\init.py\u001b[0m in \u001b[0;36m_calculate_fan_in_and_fan_out\u001b[1;34m(tensor)\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_calculate_fan_in_and_fan_out\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 272\u001b[1;33m     \u001b[0mdimensions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    273\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdimensions\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\test\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 778\u001b[1;33m         raise ModuleAttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[0;32m    779\u001b[0m             type(self).__name__, name))\n\u001b[0;32m    780\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleAttributeError\u001b[0m: 'Conv2d' object has no attribute 'dim'"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 8, 3)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(16,32,2)\n",
    "        self.conv3 = nn.Conv2d(32,64,3)\n",
    "        self.conv4 = nn.Conv2d(64,128,3)\n",
    "        self.fc1 = nn.Linear(64 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 256)\n",
    "        self.fc3 = nn.Linear(256,128)\n",
    "        self.fc4 = nn.Linear(128, 10)\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.conv1, gain=1.)\n",
    "        nn.init.xavier_uniform_(self.conv2, gain=1.)\n",
    "        nn.init.xavier_uniform_(self.conv3, gain=1.)\n",
    "        nn.init.xavier_uniform_(self.conv4, gain=1.)\n",
    "        \n",
    "        nn.init.normal_(self.fc1.weight.data)\n",
    "        nn.init.normal_(self.fc2.weight.data)\n",
    "        nn.init.normal_(self.fc3.weight.data)\n",
    "        nn.init.normal_(self.fc4.weight.data)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool(F.relu(self.conv4(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "for epoch in range(5):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i in range(len(train_data)):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = torch.tensor(train_data[i], dtype=torch.float), torch.tensor(train_labels[i], dtype=torch.float)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
